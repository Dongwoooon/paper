{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USPTO의 XML data 처리\n",
    "\n",
    "1. USPTO는 XML 형태, 매주 목요일 기준으로 application 데이터 공개\n",
    "2. App NO, DN, Assignee, Class, Filed date, Country 정보 추출 가능\n",
    "3. 2002 - 2004, 2005 ~ 2013 apps 정보 추출 ㄱㄱ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. xml 파일 처리\n",
    "\n",
    "- USPTO가 제공하는 xml은 multiroot \n",
    "- 각 app이 하나의 xml, 그걸 그냥 모아놓은 거\n",
    "- __따라서 app 1개씩 잘라야 xml parsing이 가능__\n",
    "- https://github.com/funginstitute/patentprocessor/blob/master/parse.py 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import xml.etree.ElementTree as et\n",
    "import datetime as dt\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')  # to process name of assignee in unicode \n",
    "os.chdir('E:/apps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_xml_strings(filename):\n",
    "    # search for terminating XML tag\n",
    "    endtag_regex = re.compile('^<!DOCTYPE (.*) SYSTEM')\n",
    "    endtag = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        doc = ''  # initialize current XML doc to empty string\n",
    "        for line in f:\n",
    "            doc += line\n",
    "            endtag = endtag_regex.findall(line) if not endtag else endtag   #is there any endtags?\n",
    "            if not endtag:\n",
    "                continue      #if there's no end tag, keep the loop going\n",
    "            terminate = re.compile('^</{0}>'.format(endtag[0]))    #if there's a end tag, then check whether the doc is finished or not\n",
    "            if terminate.findall(line):     #if there's a terminator\n",
    "                yield (doc)                 #export doc and reinitialize a doc\n",
    "                endtag = ''\n",
    "                doc = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. csv 파일 만들기\n",
    "- csv 2개 만들 거\n",
    "- dn, app no, assignee, country, date 담은 csv  \n",
    "- dn, app no, class 담은 csv\n",
    "- 각 정보 list에 담고 그걸 line으로 해서 csv 쓰자\n",
    "- 문제는 02 ~ 04와 05 ~ 13 xml 구조가 다름  \n",
    "    => 02 ~ 04 csv 만든 후, 그 밑에 05 ~ 13 붙이자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__code 구조__\n",
    "- filename 제작\n",
    "- xml 불러와서 쪼개기\n",
    "- 쪼갠 xml parsing해서 원하는 정보 뽑기  \n",
    "    dn, appno, date : app 당 1개 뿐 -> 찍어서 뽑기   \n",
    "    assignee, country, class : 여러 개 가능 -> iter 사용\n",
    "- list에 담고 writing csv\n",
    "- date +1주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xml 뽑을 element (02 ~ 04)__\n",
    "- DN : ~ / doc-number 첫 번째\n",
    "- APP No : ~ / doc-number 두 번째\n",
    "- Filed date (02 ~ 04) : subdoc-bibliographic-information / domestic-filing-data / filing-date    \n",
    "- Class (02 ~ 04) : ~ / uspc / class, subclass  \n",
    "    **issue : 3digit에서 0 제거 안 함  __ex) 312/29.1 = 312029001 => classmaker fn 사용__    \n",
    "- Assignee : assignee / organization-name   \n",
    "- Country : assignee / country / country-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xml 뽑을 element (05 ~ 13)__\n",
    "- DN : ~ / doc-number 첫 번째\n",
    "- APP No : ~ / doc-number 두 번째\n",
    "- Filed date (05 ~ 13) : us-bibliographic-data-application / application-reference / documnet-id / date\n",
    "- Class : us-bibliographic-data-application / classification-national / main-classification  \n",
    "    **issue : 3digit에서 0 or 공백 제거 안 함  __ex) 312/29.1 = 312029001 or 312 291  => classmaker fn 사용__    \n",
    "- Assignee : us-bibliographic-data-application / assignees / addressbook / orgname   \n",
    "- Country : us-bibliographic-data-application / assignees / addressbook / address / country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def digitize(cls):\n",
    "    try :\n",
    "        return str(int(cls))\n",
    "    except ValueError:\n",
    "        if cls[0] == '0':\n",
    "            cls=cls.replace('0','')\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classmaker(cls,line):\n",
    "    try:\n",
    "        cls=cls.replace(' ','0')\n",
    "        if len(cls) < 9:\n",
    "            for i in range(9-len(cls)):\n",
    "                cls += '0'\n",
    "\n",
    "        line.append(digitize(cls[0:3]))\n",
    "        if digitize(cls[6:9])=='0':\n",
    "            line.append(digitize(cls[3:6]))\n",
    "        else:\n",
    "            sub = (lambda x,y: x + '.' + y)(digitize(cls[3:6]),digitize(cls[6:9]))\n",
    "            line.append(sub)\n",
    "    except AttributeError:      # due to missing value\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2002 ~ 2004는 html 섞여있나 이상한 entity 있음 -> entity 에러 제거 위해 parser 처리 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllEntities:\n",
    "    def __getitem__(self, key):\n",
    "        #key is your entity, you can do whatever you want with it here\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date = '20020103'  #initializing date\n",
    "\n",
    "with open('app_profile.csv', 'wb') as prf, open('app_class.csv', 'wb') as cls:\n",
    "    prf_writer = csv.writer(prf,quoting=csv.QUOTE_ALL)\n",
    "    cls_writer = csv.writer(cls,quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    prf_writer.writerow(['number','id','date','assignee','country'])\n",
    "    cls_writer.writerow(['number','id','mainclass','subclass','further_m','further_s'])\n",
    "    \n",
    "    while not date=='20050106':\n",
    "        filename = 'xmls/ipab'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            parser = et.XMLParser()\n",
    "            parser.parser.UseForeignDTD(True)\n",
    "            parser.entity = AllEntities()\n",
    "            root = et.fromstring(doc, parser=parser)\n",
    "            n = root.iter('doc-number')\n",
    "            dn = n.next().text\n",
    "            appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "            \n",
    "            n = root.iter('filing-date')\n",
    "            fdate = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(n.next().text)\n",
    "            \n",
    "            aline = [dn,appno,fdate]\n",
    "            cline = [dn,appno]\n",
    "            \n",
    "            for ass in root.iter('assignee'):   #using iter because of multi-assignee apps \n",
    "                for n in ass.iter(\"organization-name\"):    #to deal with name-missed assignees\n",
    "                    name = n.text\n",
    "                    aline.append(name)\n",
    "                \n",
    "                for n in ass.iter(\"country-code\"):    #to deal with country-missed assignees\n",
    "                    country = n.text\n",
    "                    aline.append(country)    \n",
    "                \n",
    "            aline.append('private') if len(aline)==3 else aline\n",
    "            \n",
    "            for cls in root.iter('uspc'):  #using iter because of multi-class apps\n",
    "                rawclass = cls[0].text + cls[1].text\n",
    "                classmaker(rawclass,cline)           \n",
    "                          \n",
    "            prf_writer.writerow(aline)\n",
    "            cls_writer.writerow(cline)\n",
    "        \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** issue: country code에 이상한 거 많음 (기업 이름, 공백 포함 - US vs ' 'US) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2005 ~ 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-13e92c8d88d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'main-classification'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#using iter because of multi-class apps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mrawclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mclassmaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawclass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'further-classification'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#using iter because of multi-class apps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f5d20665c774>\u001b[0m in \u001b[0;36mclassmaker\u001b[0;34m(cls, line)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassmaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcls\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "date = '20050106'  #initializing date\n",
    "\n",
    "with open('app_profile.csv', 'ab') as prf, open('app_class.csv', 'ab') as cls:\n",
    "    prf_writer = csv.writer(prf,quoting=csv.QUOTE_ALL)\n",
    "    cls_writer = csv.writer(cls,quoting=csv.QUOTE_ALL)\n",
    "       \n",
    "    while not date=='20140102':\n",
    "        filename = 'xmls/ipab'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            root = et.fromstring(doc)\n",
    "            n = root.iter('doc-number')\n",
    "            dn = n.next().text\n",
    "            appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "            fdate = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(root[0][1][0][2].text)\n",
    "                \n",
    "            aline = [dn,appno,fdate]\n",
    "            cline = [dn,appno]\n",
    "            \n",
    "            for ass in root.iter('assignee'):   #using iter because of multi-assignee apps \n",
    "                for n in ass.iter(\"orgname\"):    #to deal with name-missed assignees\n",
    "                    name = n.text\n",
    "                    aline.append(name)\n",
    "                \n",
    "                for n in ass.iter(\"country\"):    #to deal with country-missed assignees\n",
    "                    country = n.text\n",
    "                    aline.append(country) \n",
    "                \n",
    "            aline.append('private') if len(aline)==3 else aline\n",
    "            \n",
    "            for cls in root.iter('main-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "            \n",
    "            for cls in root.iter('further-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "                          \n",
    "            prf_writer.writerow(aline)\n",
    "            cls_writer.writerow(cline)\n",
    "        \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와 나 class에도 missing이 있네? ㅁㅊ... classmaker 함수 수정 후 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20080221'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20080044287'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '20080221'  #initializing date\n",
    "\n",
    "with open('app_profile.csv', 'ab') as prf, open('app_class.csv', 'ab') as cls:\n",
    "    prf_writer = csv.writer(prf,quoting=csv.QUOTE_ALL)\n",
    "    cls_writer = csv.writer(cls,quoting=csv.QUOTE_ALL)\n",
    "       \n",
    "    while not date=='20140102':\n",
    "        filename = 'xmls/ipab'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            root = et.fromstring(doc)\n",
    "            n = root.iter('doc-number')\n",
    "            dn = n.next().text\n",
    "            appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "            fdate = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(root[0][1][0][2].text)\n",
    "                \n",
    "            aline = [dn,appno,fdate]\n",
    "            cline = [dn,appno]\n",
    "            \n",
    "            for ass in root.iter('assignee'):   #using iter because of multi-assignee apps \n",
    "                for n in ass.iter(\"orgname\"):    #to deal with name-missed assignees\n",
    "                    name = n.text\n",
    "                    aline.append(name)\n",
    "                \n",
    "                for n in ass.iter(\"country\"):    #to deal with country-missed assignees\n",
    "                    country = n.text\n",
    "                    aline.append(country) \n",
    "                \n",
    "            aline.append('private') if len(aline)==3 else aline\n",
    "            \n",
    "            for cls in root.iter('main-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "            \n",
    "            for cls in root.iter('further-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "                          \n",
    "            prf_writer.writerow(aline)\n",
    "            cls_writer.writerow(cline)\n",
    "        \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
