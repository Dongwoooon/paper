{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fung data (assignee, patent) 붙여서 하나로 만들기\n",
    "\n",
    "### patent assigned to an individual 분리 필요\n",
    "- 개인이 갖고 있는 patent는 우리 관심 밖\n",
    "- 그런데 Fung data의 disambiguated assignee에는 개인도 섞여 있음\n",
    "- 개인 patent의 assignee를 'private'으로 바꿔주자\n",
    "\n",
    "### Assignee 정보와 Patent 정보 붙이기\n",
    "- patent 하나에 assignee 여럿일 수 있음\n",
    "- 우리의 목표는 firm level로 aggregate\n",
    "- 따라서 assignee 기준으로 left join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 기존 raw patent data에서 patent_id (5,6,7번대), private dummy 뽑음\n",
    "2. 뽑은 애들이랑 Fung data iterate 하면서 assingee를 private으로 바꾸기\n",
    "3. assignee와 patent patent_id 기준으로 join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 기존 raw patent data에서 id, assignee 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import csv\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "os.chdir('E:/patent')\n",
    "\n",
    "zf_patent1 = zipfile.ZipFile('all_patent/harvard_dataset_final_merged_output_1.zip') \n",
    "csv_patent1 = zf_patent1.open('harvard_dataset_final_merged_output_1.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "header=csv_patent_reader1.next()\n",
    "\n",
    "zf_patent2 = zipfile.ZipFile('all_patent/harvard_dataset_final_merged_output_2.zip')\n",
    "csv_patent2 = zf_patent2.open('harvard_dataset_final_merged_output_2.csv')\n",
    "csv_patent_reader2 = csv.reader(csv_patent2)\n",
    "\n",
    "header2=csv_patent_reader2.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select the assignee col\n",
    "for i, name in enumerate(header):\n",
    "    if 'organization_0' in name:   \n",
    "        assignee_col = i\n",
    "        break\n",
    "        \n",
    "assignee_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index: patent_id == 1, assignee == 19500  \n",
    "private의 경우, assignee = 'nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pid_private.csv','wb') as private:\n",
    "    writer = csv.writer(private)\n",
    "    header = ['patent_id','private']\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for i in xrange(1000000):\n",
    "        csv_patent_reader1.next()\n",
    "    \n",
    "    pid = ['5','6']    \n",
    "    for line in csv_patent_reader1:\n",
    "        if line[1][0] in pid and line[19500] == 'nan':\n",
    "            row=[]\n",
    "            row.append(line[1])\n",
    "            row.append(1)\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    pid = ['6','7']    \n",
    "    for line in csv_patent_reader2:\n",
    "        if line[1][0] in pid and line[19500] == 'nan':\n",
    "            row=[]\n",
    "            row.append(line[1])\n",
    "            row.append(1)\n",
    "            writer.writerow(row)   \n",
    "        \n",
    "        elif line[1][0]=='8':\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. private으로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "os.chdir('E:/')\n",
    "\n",
    "df1 = pd.read_csv('apps/fung/assignee_1.csv')\n",
    "df2 = pd.read_csv('apps/fung/assignee_2.csv')\n",
    "df3 = pd.read_csv('apps/fung/assignee_3.csv')\n",
    "\n",
    "df = df1.append([df2, df3], ignore_index=True)\n",
    "del df1, df2, df3\n",
    "\n",
    "with open('patent/pid_private.csv','rb') as prv:\n",
    "    reader = csv.reader(prv)\n",
    "    reader.next()\n",
    "    line = reader.next()\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        a=line[0]\n",
    "        if row['patent_id'] == int(line[0]):\n",
    "            df.loc[i,'assignee'] = 'private'\n",
    "            line = reader.next()\n",
    "\n",
    "df.to_csv('apps/fung/assignee.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('apps/fung/patent_1.csv')\n",
    "df2 = pd.read_csv('apps/fung/patent_2.csv')\n",
    "df3 = pd.read_csv('apps/fung/patent_3.csv')\n",
    "\n",
    "df1 = df1.append([df2, df3], ignore_index=True)\n",
    "del df2, df3\n",
    "\n",
    "df1.to_csv('apps/fung/patent_vars.csv', index=False)\n",
    "df = df.merge(df1, on='patent_id', how='left', sort=True)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[1:4] + cols[0:1] + cols[4:]\n",
    "df = df[cols]\n",
    "\n",
    "df.to_csv('apps/fung/patent_fung.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('patent_fung.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
