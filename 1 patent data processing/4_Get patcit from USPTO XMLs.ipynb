{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patent가 인용한 patent 찾기\n",
    "\n",
    "### 추출할 element\n",
    "patent_id: 첫 doc-number  \n",
    "pat_cited: citation / patcit / document-id / country='US' & len(doc-number) == 7 => **country != 'US'에서 탈출** (다음 doc으로 ㄱㄱ)   \n",
    "examiner: citation / category\n",
    "\n",
    "### some issues on the elements\n",
    "**patent_id**\n",
    "- 맨 앞이 D로 시작하는 애들 때문에 D없는 애들 앞에 0이 붙음   \n",
    "- but, 우리가 관심있는 특허는 D로 시작하는 애들 없음  \n",
    "- **=> int 만들어서 0 떼고 value Error 뜨면 바로 다음 doc으로 넘겨버리자**\n",
    "  \n",
    "**examiner**  \n",
    "- dummy로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import xml.etree.ElementTree as et\n",
    "import datetime as dt\n",
    "\n",
    "os.chdir('E:/apps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_xml_strings(filename):\n",
    "    \"\"\"\n",
    "    Given a string [filename], opens the file and returns a generator\n",
    "    that yields tuples. A tuple is of format (year, xmldoc string). A tuple\n",
    "    is returned for every valid XML doc in [filename]\n",
    "    \"\"\"\n",
    "    # search for terminating XML tag\n",
    "    endtag_regex = re.compile('^<!DOCTYPE (.*) SYSTEM')\n",
    "    endtag = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        doc = ''  # initialize current XML doc to empty string\n",
    "        for line in f:\n",
    "            doc += line\n",
    "            endtag = endtag_regex.findall(line) if not endtag else endtag   #is there any endtags?\n",
    "            if not endtag:\n",
    "                continue      #if there's no end tag, keep the loop going\n",
    "            terminate = re.compile('^</{0}>'.format(endtag[0]))    #if there's a end tag, then check whether the doc is finished or not\n",
    "            if terminate.findall(line):     #if there's a terminator\n",
    "                yield (doc)                 #export doc and reinitialize a doc\n",
    "                endtag = ''\n",
    "                doc = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__파일 크기 너무 클테니 두 개로 쪼갬 05~08, 09~12__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "date = '20050104'  #initializing date\n",
    "\n",
    "with open('pat_citation_1.csv', 'wb') as cit:\n",
    "    writer = csv.writer(cit,quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    while not date=='20090106':\n",
    "        filename = 'pat_xmls/ipgb'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            root = et.fromstring(doc)\n",
    "            n = root.iter('doc-number')\n",
    "            pid = n.next().text\n",
    "\n",
    "            try:\n",
    "                pid = int(pid)                          \n",
    "                for cit in root.iter('citation'):   #using iter because of multi-assignee apps \n",
    "                    did = cit[0][0]\n",
    "                    try:\n",
    "                        cited = cit[1].text              \n",
    "                        try:\n",
    "                            if did.find('country').text != 'US':  #if foreign cit, go to next doc\n",
    "                                break \n",
    "\n",
    "                            cid = did.find('doc-number').text\n",
    "                            if len(cid) > 8:     #if app cit, go to next doc\n",
    "                                break\n",
    "                            \n",
    "                            cit_dum = 1 if cited.split()[-1] == 'examiner' else 0\n",
    "\n",
    "                            writer.writerow([pid,cid,cit_dum])\n",
    "\n",
    "                        except AttributeError:         #if other cit, go to next doc\n",
    "                            break\n",
    "                        \n",
    "                    except IndexError:    #if other cit, go to next doc\n",
    "                        break\n",
    "                        \n",
    "            except ValueError:      #if pid != int, go to the next doc\n",
    "                continue    \n",
    "                             \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = '20090106'  #initializing date\n",
    "\n",
    "with open('pat_citation_2.csv', 'wb') as cit:\n",
    "    writer = csv.writer(cit,quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    while not date=='20130101':\n",
    "        filename = 'pat_xmls/ipgb'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            root = et.fromstring(doc)\n",
    "            n = root.iter('doc-number')\n",
    "            pid = n.next().text\n",
    "\n",
    "            try:\n",
    "                pid = int(pid)                          \n",
    "                for cit in root.iter('citation'):   #using iter because of multi-assignee apps \n",
    "                    did = cit[0][0]\n",
    "                    try:\n",
    "                        cited = cit[1].text              \n",
    "                        try:\n",
    "                            if did.find('country').text != 'US':  #if foreign cit, go to next doc\n",
    "                                break \n",
    "\n",
    "                            cid = did.find('doc-number').text\n",
    "                            if len(cid) > 8:     #if app cit, go to next doc\n",
    "                                break\n",
    "                            \n",
    "                            cit_dum = 1 if cited.split()[-1] == 'examiner' else 0\n",
    "\n",
    "                            writer.writerow([pid,cid,cit_dum])\n",
    "\n",
    "                        except AttributeError:         #if other cit, go to next doc\n",
    "                            break\n",
    "                        \n",
    "                    except IndexError:    #if other cit, go to next doc\n",
    "                        break\n",
    "                        \n",
    "            except ValueError:      #if pid != int, go to the next doc\n",
    "                continue    \n",
    "                             \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### examiner or firm 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10218430"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('E:/apps')\n",
    "df = pd.read_csv('pat_citation_1.csv')\n",
    "df.sort_values(by='patent_id',inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6884027"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[df['by_examiner']==0]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df1['by_examiner']\n",
    "df1.to_csv('pat_citation_byfirm_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16823021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df1\n",
    "\n",
    "df = pd.read_csv('pat_citation_2.csv')\n",
    "df.sort_values(by='patent_id',inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12810011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[df['by_examiner']==0]\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df1['by_examiner']\n",
    "df1.to_csv('pat_citation_byfirm_2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
