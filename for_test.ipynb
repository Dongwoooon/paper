{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml 파일 쪼개기\n",
    "\n",
    "### 각 application이 하나의 xml 파일 그 자체    \n",
    "__=> 하나씩 잘라야 함__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import xml.etree.ElementTree as et\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')  # to process name of assignee in unicode \n",
    "os.chdir('J:/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('sample.xml', 'r')\n",
    "endtag_regex = re.compile('^<!DOCTYPE (.*) SYSTEM')\n",
    "endtag = ''\n",
    "doc=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = f.readline()\n",
    "doc += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endtag_regex.findall(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endtag = endtag_regex.findall(line) if not endtag else endtag\n",
    "endtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not endtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terminate = re.compile('^</{0}>'.format(endtag[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terminate.findall(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if not ~ else? 이게 뭐지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not endtag == True:\n",
    "    endtag = endtag_regex.findall(line)\n",
    "else:\n",
    "    endtag\n",
    "\n",
    "endtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아하 이렇게 쓰기 싫어서 그냥 한 줄로 끝냈구만!  \n",
    "함수 이해 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_xml_strings(filename):\n",
    "    \"\"\"\n",
    "    Given a string [filename], opens the file and returns a generator\n",
    "    that yields tuples. A tuple is of format (year, xmldoc string). A tuple\n",
    "    is returned for every valid XML doc in [filename]\n",
    "    \"\"\"\n",
    "    # search for terminating XML tag\n",
    "    endtag_regex = re.compile('^<!DOCTYPE (.*) SYSTEM')\n",
    "    endtag = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        doc = ''  # initialize current XML doc to empty string\n",
    "        for line in f:\n",
    "            doc += line\n",
    "            endtag = endtag_regex.findall(line) if not endtag else endtag   #is there any endtags?\n",
    "            if not endtag:\n",
    "                continue      #if there's no end tag, keep the loop going\n",
    "            terminate = re.compile('^</{0}>'.format(endtag[0]))    #if there's a end tag, then check whether the doc is finished or not\n",
    "            if terminate.findall(line):     #if there's a terminator\n",
    "                yield (doc)                 #export doc and reinitialize a doc\n",
    "                endtag = ''\n",
    "                doc = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = extract_xml_strings('sample.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in sample:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good~ 이젠 sample.next 해서 각 doc을 parsing, App Np, DN, assignee, class 추출하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xml 자동으로 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "application xml 파일이 1주일 단위로 구성  \n",
    "ex) ipab20070308, ipab20070315, ...  \n",
    "규칙에 맞게 자동으로 불러오도록 만들자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 날짜 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '20070301'\n",
    "date = dt.datetime.strptime(date,'%Y%m%d')\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date += dt.timedelta(weeks=1)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date=date.strftime('%Y%m%d')\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'ipab'+ date + '.xml'\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = extract_xml_strings(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 XML에서 원하는 element 뽑기\n",
    "\n",
    "App NO, DN, Assignee, Class, Filed date, Country 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "일단 각각 element가 뭔지 보면 (등장 순서대로)  \n",
    "DN : us-bibliographic-data-application / publication-reference / document-id / doc-number  \n",
    "APP No : us-bibliographic-data-application / application-reference / documnet-id / doc-number  \n",
    "Filed date : us-bibliographic-data-application / application-reference / documnet-id / date  \n",
    "Class : us-bibliographic-data-application / classification-national / main-classification  \n",
    "__** issue : 3digit에서 0 제거 안 함__  ex) 312/29.1 = 312029001  \n",
    "Assignee : us-bibliographic-data-application / assignees / addressbook / orgname  \n",
    "Country : us-bibliographic-data-application / assignees / addressbook / address / country  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = sample.next()\n",
    "doc2 = sample.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = et.fromstring(doc1)\n",
    "root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list 만들어서 각 정보들 넣은 후, csv로 바꾸자  \n",
    "dn, app no, assignee, country, date 담은 csv  \n",
    "dn, app no, class 담은 csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in root.iter('doc-number'):\n",
    "    dn = n.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = root.iter('doc-number')\n",
    "dn = n.next().text\n",
    "appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "print dn, type(dn), appno, type(appno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DN, APP NO, country, date 얻기\n",
    "dn = root[0][0][0][1].text\n",
    "appno = (lambda x: x[0:2] + '/' + x[2:8])(root[0][1][0][1].text)\n",
    "date = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(root[0][1][0][2].text)\n",
    "\n",
    "aline = [dn,appno,date]\n",
    "cline = [dn,appno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assignee 얻기 (assignee는 복수일 수 있으니 iter 사용)\n",
    "for ass in root.iter('assignee'):\n",
    "    for name in ass.iter(\"orgname\"):\n",
    "        aline.append(name.text)\n",
    "    for country in ass.iter(\"country\"):\n",
    "        aline.append(country.text)\n",
    "\n",
    "aline.append('private') if len(aline)==3 else aline\n",
    "aline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitize(cls):\n",
    "    try :\n",
    "        return str(int(cls))\n",
    "    except ValueError:\n",
    "        if cls[0] == '0':\n",
    "            cls=cls.replace('0','')\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classmaker(cls,line):\n",
    "    cls=cls.replace(' ','0')\n",
    "    if len(cls) < 9:\n",
    "        for i in range(9-len(cls)):\n",
    "            cls += '0'\n",
    "\n",
    "    line.append(digitize(cls[0:3]))\n",
    "    if digitize(cls[6:9])=='0':\n",
    "        line.append(digitize(cls[3:6]))\n",
    "    else:\n",
    "        sub = (lambda x,y: x + '.' + y)(digitize(cls[3:6]),digitize(cls[6:9]))\n",
    "        line.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class 얻기 (class는 복수일 수 있으니 iter 사용)\n",
    "for ass in root.iter('main-classification'):\n",
    "    rawclass = ass.text\n",
    "    cline.append(classmaker(rawclass[0:3]))\n",
    "    if not int(rawclass[6:9]):\n",
    "        cline.append(classmaker(rawclass[3:6]))\n",
    "    else:\n",
    "        sub = (lambda x,y: x + '.' + y)(classmaker(rawclass[3:6]),classmaker(rawclass[6:9]))\n",
    "        cline.append(sub)\n",
    "\n",
    "cline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02 ~ 04랑 05 ~ 13이 구조적으로 완전 다르네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AllEntities:\n",
    "    def __getitem__(self, key):\n",
    "        #key is your entity, you can do whatever you want with it here\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = et.XMLParser()\n",
    "parser._parser.UseForeignDTD(True)\n",
    "parser.entity = AllEntities()\n",
    "root = et.fromstring(doc1,parser=parser)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '20070308'  #initializing date\n",
    "\n",
    "with open('app_profile.csv', 'wb') as prf, open('app_class.csv', 'wb') as cls:\n",
    "    prf_writer = csv.writer(prf,quoting=csv.QUOTE_ALL)\n",
    "    cls_writer = csv.writer(cls,quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    prf_writer.writerow(['number','id','date','assignee','country'])\n",
    "    cls_writer.writerow(['number','id','mainclass','subclass','further_m','further_s'])\n",
    "    \n",
    "    while not date=='20070315':\n",
    "        filename = 'xmls/ipab'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            parser = et.XMLParser()\n",
    "            parser.parser.UseForeignDTD(True)\n",
    "            parser.entity = AllEntities()\n",
    "            root = et.fromstring(doc, parser=parser)\n",
    "            n = root.iter('doc-number')\n",
    "            dn = n.next().text\n",
    "            appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "            \n",
    "            n = root.iter('filing-date')\n",
    "            fdate = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(n.next().text)\n",
    "            \n",
    "            aline = [dn,appno,fdate]\n",
    "            cline = [dn,appno]\n",
    "            \n",
    "            for ass in root.iter('assignee'):   #using iter because of multi-assignee apps \n",
    "                name = ass.iter(\"organization-name\").next().text\n",
    "                aline.append(name)\n",
    "                \n",
    "                for n in ass.iter(\"country-code\"):    #to deal with country-missed assignees\n",
    "                    country = n.text\n",
    "                    aline.append(country)    \n",
    "                \n",
    "            aline.append('private') if len(aline)==3 else aline\n",
    "            \n",
    "            for cls in root.iter('uspc'):  #using iter because of multi-class apps\n",
    "                rawclass = cls[0].text + cls[1].text\n",
    "                classmaker(rawclass,cline)           \n",
    "                          \n",
    "            prf_writer.writerow(aline)\n",
    "            cls_writer.writerow(cline)\n",
    "        \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = '20070315'  #initializing date\n",
    "\n",
    "with open('app_profile.csv', 'ab') as prf, open('app_class.csv', 'ab') as cls:\n",
    "    prf_writer = csv.writer(prf,quoting=csv.QUOTE_ALL)\n",
    "    cls_writer = csv.writer(cls,quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    while not date=='20070329':\n",
    "        filename = 'xmls/ipab'+ date + '.xml'   #making filename\n",
    "        xml = extract_xml_strings(filename)   #load and split whole xml into app_xmls  \n",
    "        for doc in xml:\n",
    "            root = et.fromstring(doc)\n",
    "            n = root.iter('doc-number')\n",
    "            dn = n.next().text\n",
    "            appno = (lambda x: x[0:2] + '/' + x[2:8])(n.next().text)\n",
    "            fdate = (lambda x: x[0:4] + '-' + x[4:6] + '-' + x[6:8])(root[0][1][0][2].text)\n",
    "                \n",
    "            aline = [dn,appno,fdate]\n",
    "            cline = [dn,appno]\n",
    "            \n",
    "            for ass in root.iter('assignee'):   #using iter because of multi-assignee apps \n",
    "                name = ass.iter(\"orgname\").next().text\n",
    "                aline.append(name)\n",
    "                \n",
    "                for n in ass.iter(\"country\"):    #to deal with country-missed assignees\n",
    "                    country = n.text\n",
    "                    aline.append(country)    \n",
    "                \n",
    "            aline.append('private') if len(aline)==3 else aline\n",
    "            \n",
    "            for cls in root.iter('main-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "            \n",
    "            for cls in root.iter('further-classification'):  #using iter because of multi-class apps\n",
    "                rawclass = cls.text\n",
    "                classmaker(rawclass,cline)\n",
    "                          \n",
    "            prf_writer.writerow(aline)\n",
    "            cls_writer.writerow(cline)\n",
    "        \n",
    "        date = dt.datetime.strptime(date,'%Y%m%d')   #Let's move on to next xml\n",
    "        date += dt.timedelta(weeks=1)\n",
    "        date = date.strftime('%Y%m%d')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy로 grant dummy 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge 후 granted_dum_i, granted_dum_i 중 __하나만 NaN 일 때__ 정상  \n",
    "둘 다 NaN일 경우 (matching 실패) or 둘 다 NaN 아닐 경우 (matching 중복) 처리 필요  \n",
    "=> numpy array로 처리 후 다시 갖다 붙이자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(  1.,  nan), (  0.,  nan), ( nan,  nan), ( nan,  nan),\n",
       "       ( nan,   0.), ( nan,   1.), ( nan,   2.), (  1.,   1.),\n",
       "       (  0.,   0.), (  1.,   2.), (  0.,   2.), (  1.,   2.),\n",
       "       (  0.,   2.), (  1.,   1.), (  1.,   0.), (  0.,   1.),\n",
       "       (  0.,   1.), (  1.,  nan), (  0.,  nan)], \n",
       "      dtype=[('granted_dum_i', '<f8'), ('granted_dum_n', '<f8')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummy 뒷처리\n",
    "\n",
    "dum = np.genfromtxt('grtdum_temp.csv',delimiter=',',dtype=float,names=True)\n",
    "dum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=dum[0]\n",
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granted_dum(arr):\n",
    "    a = arr[0] + arr[1]\n",
    "    if math.isnan(a):\n",
    "        if not math.isnan(arr[0]):\n",
    "            a = arr[0]\n",
    "        else:\n",
    "            a = arr[1] if not math.isnan(arr[1]) else a\n",
    "            a = np.nan if a==2 else a\n",
    "     \n",
    "    else:\n",
    "        if a==2:\n",
    "            if arr[0]==arr[1]:\n",
    "                a=1\n",
    "            \n",
    "            else:\n",
    "                a=0\n",
    "        \n",
    "        elif a==3:\n",
    "            a=1\n",
    "            \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vfunc = np.vectorize(granted_dum)\n",
    "result = vfunc(dum)\n",
    "np.savetxt('result.csv', result,delimiter=',', fmt='%1.1f', header='granted_dum', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   0.,  nan,  nan,   0.,   1.,  nan,   1.,   0.,   1.,   0.,\n",
       "         1.,   0.,   1.,   1.,   1.,   1.,   1.,   0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('result.csv', result,delimiter=',', fmt='%1.1f', header='granted_dum', comments='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
